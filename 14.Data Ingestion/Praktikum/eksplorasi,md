-Ekstraksi Data dari API:
Gunakan Python untuk mengirim permintaan HTTP ke https://gist.githubusercontent.com/nadirbslmh/8922f71875948802321ef479a017f4c0/raw/1fbbc4b3d55f8ae717eb197d9aaf530ed1bc7ed2/sample.json dan terima respons dalam format JSON.
Ekstrak data buku yang relevan dari respons JSON, seperti judul, pengarang, tahun terbit, dan genre.
-Pembuatan DAG di Apache Airflow:
Buat DAG di Apache Airflow untuk menjadwalkan dan mengotomatisasi proses ekstraksi data ini.
Tentukan jadwal eksekusi menggunakan cron expression, misalnya setiap minggu pada hari Senin jam 09:00.
-Integrasi Skrip Python untuk Ekstraksi Data:
Integrasikan skrip Python yang telah Anda buat untuk ekstraksi data ke dalam task di Airflow menggunakan PythonOperator.
-Pengujian dan Monitoring:
Jalankan DAG dan monitor prosesnya melalui UI Airflow.
Pastikan data berhasil diambil dan diolah sesuai jadwal yang ditentukan.

![alt text](https://github.com/abdansyakur14002/DE_Abdan-Syakur/blob/main/14.Data%20Ingestion/screenshot/eksplorasi_graph.jpg)

![alt text](https://github.com/abdansyakur14002/DE_Abdan-Syakur/blob/main/14.Data%20Ingestion/screenshot/eksplorasi_logs.jpg)
